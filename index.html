<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9KZDNK35J"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9KZDNK35J');
</script>
	<title>Self-supervised Video Object Segmentation by Motion Grouping</title>
	<meta property="og:image" content="./resources/teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Self-supervised Video Object Segmentation by Motion Grouping" />
	<meta property="og:description" content="C. Yang, H. Lamdouar, E. Lu, A. Zisserman, W. Xie" />
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">Self-supervised Video Object Segmentation by Motion Grouping</span>
		<table align=center width=1000px>
			<table align=center width=1000px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:22px"><a href="https://charigyang.github.io/">
							Charig Yang</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:22px"><a href="https://twitter.com/hala_lamdouar/">
							Hala Lamdouar</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:22px"><a href="https://erikalu.com/">
							Erika Lu</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:22px"><a href="https://www.robots.ox.ac.uk/~az/">
							Andrew Zisserman</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:22px"><a href="https://weidixie.github.io/weidi-personal-webpage/">
							Weidi Xie</a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=500px>
				<tr>
					<td align=center width=500px>
						<center>
							<span style="font-size:22px">Visual Geometry Group, University of Oxford</span>
						</center>
					</td>
				</tr>
			</table>

			
						<table align=center width=500px>
				<tr>
					<td align=center width=500px>
						<center>
							<span style="font-size:22px">ICCV 2021</span>
						</center>
					</td>
				</tr>
			</table>
			
			<table align=center width=250px>
				<br>
				<tr>
					<span style="font-size:22px">
				<a href="./resources/motiongroup.pdf">PDF</a> | 
				<a href="https://arxiv.org/abs/2104.07658">ArXiv</a> | 
				<a href="https://github.com/charigyang/motiongrouping">Code</a> | 
					<a href="./resources/bibtex.txt">Bibtex</a><br></span>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=1000px>
			<tr>
				<td width=1000px>
					<center>
						<img class="round" style="width:1000px" src="./resources/method_diagram.png"/>
					</center>
				</td>
			</tr>
		</table>
		<!--
		<table align=center width=850px>
			<tr>
				<td>
					This was a template originally made for <a href="http://richzhang.github.io/colorization/">Colorful Image Colorization</a>. The code can be found in this <a href="https://github.com/richzhang/webpage-template">repository</a>.
				</td>
			</tr>
		</table>
	-->
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Animals have evolved highly functional visual systems to understand motion,
				assisting perception even under complex environments.
				In this paper, 
				we work towards developing a computer vision system able
				to segment objects by exploiting motion cues,
				i.e. motion segmentation.
				We make the following contributions:
				First, we introduce a simple variant of the Transformer to segment optical flow frames into primary objects and the background.
				Second,
				we train the architecture in a self-supervised manner, i.e. without using any manual annotations.
				Third,
				we analyze several critical components of our method
				and conduct thorough ablation studies to validate their necessity.
				Fourth,
				we evaluate the proposed architecture on public benchmarks (DAVIS2016, SegTrackv2, and FBMS59).
				Despite using only optical flow as input,
				our approach achieves superior results compared to previous state-of-the-art self-supervised methods,
				while being an order of magnitude faster.
				We additionally evaluate on a challenging camouflage dataset (MoCA),
				significantly outperforming the other self-supervised approaches, and comparing favourably to the top supervised approach,
				highlighting the importance of motion cues,
				and the potential bias towards visual appearance in existing video segmentation models.
			</td>
		</tr>
	</table>
	<br>
	
	<hr>
	<center><h1>Video</h1></center>
	<p align="center">
		<iframe width="660" height="395" src="https://www.youtube.com/embed/ZTn0xRJvndU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
	</p>
	

	<hr>
	
	<center><h1>Results</h1></center>

	<table align=center width=750px>
		<center>
			<tr>
				<td>
				<center>
					<td><img class="round" style="width:750px" src="./resources/graph.png"/></td>
				</center>
				</td>
			</tr>
		</center>
	</table>
	<br>
	<table align=center width=1000px>
		<tr>
			<td>
	<strong>Results comparison on DAVIS2016.</strong>
	Note that, supervised approaches may use models pretrained on ImageNet,
	but here we only count number of images with pixel-wise annotations.
			</td>
		</tr>
	</table>

	<br><br>
	<table align=center width=1000px>
		<center>
			<tr>
				<td>
				<center>
					<td><img class="round" style="width:1000px" src="./resources/main.png"/></td>
				</center>
				</td>
			</tr>
		</center>
	</table>
	<br>
	<table align=center width=1000px>
		<tr>
			<td>
	<strong>Full comparison on unsupervised video segmentation.</strong>
	We consider three popular datasets, DAVIS2016, SegTrack-v2 (STv2), and FBMS59.
	Models above the horizontal dividing line are trained without using any manual annotation,
	while models below are pre-trained on image or video segmentation datasets, e.g. DAVIS, YouTube-VOS,
	thus requiring ground truth annotations at training time.
	Numbers in parentheses denote the additional usage of significant post-processing, 
	e.g. multi-step flow, multi-crop, temporal smoothing, CRFs.
			</td>
		</tr>
	</table>

	<br><br>
	<table align=center width=1000px>
		<center>
			<tr>
				<td>
				<center>
					<td><img class="round" style="width:1000px" src="./resources/moca.png"/></td>
				</center>
				</td>
			</tr>
		</center>
	</table>
	<br>
	<table align=center width=1000px>
		<tr>
			<td>
	<strong>Comparison results on MoCA dataset.</strong>
	We report the successful localization rate for various thresholds.
	Both CIS and Ours were pre-trained on DAVIS and finetuned on MoCA in a self-supervised manner.
	Note that, our method achieves comparable Jaccard to MATNet (2nd best model on DAVIS), 
	without using RGB inputs and without any manual annotation for training.
			</td>
		</tr>
	</table>


	
	<br><br>
	<hr>
	
	<center><h1>Visualizations</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td>

				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/flatfish_1.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/parachute.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/spider_tailed_horned_viper_3.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/soapbox.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/pygmy_seahorse_2.gif"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=400px>
		<tr>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/paragliding-launch.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/frog.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/drift.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/snow_leopard_2.gif"/></td>
				</center>
			</td>
			<td align=center width=200px>
				<center>
					<td><img class="round" style="width:200px" src="./resources/car-roundabout.gif"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<!--
				<td>
					Coming soon...
				</td>
			-->
			</tr>
		</center>
	</table>
	<!--
	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/charigyang/motiongrouping'>[GitHub]</a>
			</center>
		</span>
	</table>
	<br>
-->

	<hr>
	<table align=center width=800px>
		<center><h1>Publication</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">C. Yang, H. Lamdouar, E. Lu, A. Zisserman, W. Xie<br>
				<b>Self-supervised Video Object Segmentation by Motion Grouping</b><br>
				International Conference on Computer Vision (ICCV), 2021<br>
				<a href="./resources/motiongroup.pdf">PDF</a> | 
				<a href="https://arxiv.org/abs/2104.07658">ArXiv</a> | 
				<a href="https://github.com/charigyang/motiongrouping">Code</a> | 
				<a href="./resources/bibtex.txt">Bibtex</a><br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>
	<br>
	<!--
	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>-->

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This research is supported by Google-DeepMind Studentship, UK EPSRC CDT in AIMS, 
					Schlumberger Studentship, and the UK EPSRC Programme Grant Visual AI (EP/T028572/1). 
					<br>
					<br>

					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

